{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd075a88bca18d42798bd43853615f6d8e1ba2122f998d1455de99fcbfb11fe8fcf",
   "display_name": "Python 3.8.3 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\REPOS\\Kaggle\\CongressionalVotingID.shuf.lrn.csv\",na_values=['unknown'])\n",
    "data.drop('ID',axis=1,inplace=True) #DROP ID\n",
    "data.replace(('y', 'n'), (1, 0), inplace=True) #Replace Y = 1 ; N = 0\n",
    "data.head() #Y = 1; N = 0; unknown = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = data.drop('class', axis=1).columns \n",
    "z = 0\n",
    "fig, axes = plt.subplots(4, 4, figsize=(30, 15))\n",
    "for i in range(4):\n",
    "    #graphs = np.where(y_train == i)[0] # seleciona as imagens de cada tipo para ser plotada no grafico.\n",
    "    for j in range(4):     \n",
    "        sns.countplot(x = graphs[z+j], hue='class', data=data, palette='BuPu', ax=axes[i][j])\n",
    "        axes[i][j].set_yticks([])\n",
    "    z = z + j + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.replace(('democrat', 'republican'), (0, 1), inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Report dont RUN\n",
    "CongressionalVotes = pandas_profiling.ProfileReport(df)\n",
    "CongressionalVotes.to_file('CongressionalVotes.html')\n",
    "CongressionalVotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, model):\n",
    "    K = 5\n",
    "    R = 3\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits=K, n_repeats=R, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def get_models():\n",
    "    models, names = list(), list()\n",
    "    # SVM\n",
    "    models.append(LogisticRegression())\n",
    "    names.append('LG')\n",
    "    \n",
    "    models.append(KNeighborsClassifier())\n",
    "    names.append('KNN')\n",
    "    \n",
    "    models.append(RandomForestClassifier(n_estimators=1000))\n",
    "    names.append('RF')\n",
    "    \n",
    "    models.append(ExtraTreesClassifier(n_estimators=1000))\n",
    "    names.append('ET')\n",
    "    \n",
    "    return models, names\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    probs_votos = model.predict_proba(test_features)\n",
    "    accuracy = roc_auc_score(test_labels, probs_votos[:,1])\n",
    "    return accuracy"
   ]
  },
  {
   "source": [
    "imp = SimpleImputer(strategy=\"mean\")  \n",
    ">LG 0.942 (0.025)  \n",
    ">KNN 0.911 (0.031)  \n",
    ">RF 0.947 (0.022)  \n",
    ">ET 0.943 (0.029)  \n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")  \n",
    ">LG 0.937 (0.028)  \n",
    ">KNN 0.917 (0.039)  \n",
    ">RF 0.950 (0.024)  \n",
    ">ET 0.945 (0.031)  \n",
    "\n",
    "imp = SimpleImputer(strategy=\"median\")  \n",
    ">LG 0.937 (0.028)  \n",
    ">KNN 0.917 (0.039)  \n",
    ">RF 0.948 (0.024)  \n",
    ">ET 0.947 (0.031)  \n",
    "\n",
    "imp = SimpleImputer(strategy=\"constant\") No fill  \n",
    ">LG 0.940 (0.028)  \n",
    ">KNN 0.905 (0.050)  \n",
    ">RF 0.946 (0.022)  \n",
    ">ET 0.937 (0.031)  \n",
    "\n",
    "dropna()  \n",
    ">LG 0.941 (0.052)  \n",
    ">KNN 0.905 (0.064)  \n",
    ">RF 0.956 (0.042)  \n",
    ">ET 0.949 (0.041)  \n",
    "\n",
    "\n",
    "LG: 0.942 mean   \n",
    "KNN: 0.917 most_frequent  \n",
    "RF: 0.956 drop_na  \n",
    "ET: 0.949 drop_na  \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPUTED MODELS\n",
    "df_imp = df\n",
    "y = df_imp['class'].values\n",
    "X = df_imp.drop('class', axis=1).values\n",
    "\n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "X = imp.fit_transform(X)\n",
    "\n",
    "models, names = get_models()\n",
    "\n",
    "results = list()\n",
    "print(\"Model\", \"Mean\", \"Std\")\n",
    "\n",
    "for i in range(len(models)):\n",
    "    scores = evaluate_model(X, y, models[i])\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP NA\n",
    "df_na = df.dropna()\n",
    "y = df_na['class'].values\n",
    "X = df_na.drop('class', axis=1).values\n",
    "\n",
    "models, names = get_models()\n",
    "\n",
    "results = list()\n",
    "print(\"Model\", \"Mean\", \"Std\")\n",
    "\n",
    "for i in range(len(models)):\n",
    "    scores = evaluate_model(X, y, models[i])\n",
    "    results.append(scores)\n",
    "    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_na['class'].values\n",
    "X_train = df_na.drop('class', axis=1).values\n",
    "\n",
    "test = pd.read_csv(\"C:\\REPOS\\Kaggle\\CongressionalVotingID.shuf.tes.csv\",na_values=['unknown'])\n",
    "test.drop('ID',axis=1,inplace=True) #DROP ID\n",
    "test.replace(('y', 'n'), (1, 0), inplace=True) #Replace Y = 1 ; N = 0\n",
    "test.head() #Y = 1; N = 0; unknown = NaN\n",
    "df_test = test.replace(('democrat', 'republican'), (0, 1), inplace=False)\n",
    "\n",
    "df_na = df.dropna()\n",
    "\n",
    "X_test = df_test['class'].values\n",
    "y_test = df_test.drop('class', axis=1).values\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search do random forest\n",
    "# definição de cada paramentro\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Criação do grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 42)\n",
    "# avaliação cruzada utilizando 3 folds, \n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_absolute_error', \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit\n",
    "rf_random.fit(X_train, y_train)\n",
    "print('Melhores parametros:',rf_random.best_params_)\n",
    "# seleção do melhor modelo e avaliação da acuracia do modelo \n",
    "best_random = rf_random.best_estimator_\n",
    "#fazendo a predição nos arquivos de teste\n",
    "y_pred = best_random.predict(X_test)\n",
    "# avaliação da acuracia do modelo\n",
    "acc_vote = accuracy_score(y_test, y_pred)\n",
    "print(\"acuracia: \",acc_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC:\" ,evaluate(best_random, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}